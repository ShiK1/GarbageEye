{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from replace_Backbone import CSPdarkNetWithFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = CSPdarkNetWithFPN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,) (0.5, 1.0, 2.0)\n",
      "torch.Size([1]) torch.Size([3])\n",
      "torch.Size([1, 1]) torch.Size([3, 1])\n",
      "(64,) (0.5, 1.0, 2.0)\n",
      "torch.Size([1]) torch.Size([3])\n",
      "torch.Size([1, 1]) torch.Size([3, 1])\n",
      "(128,) (0.5, 1.0, 2.0)\n",
      "torch.Size([1]) torch.Size([3])\n",
      "torch.Size([1, 1]) torch.Size([3, 1])\n",
      "(256,) (0.5, 1.0, 2.0)\n",
      "torch.Size([1]) torch.Size([3])\n",
      "torch.Size([1, 1]) torch.Size([3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[-23., -11.,  23.,  11.],\n",
       "         [-16., -16.,  16.,  16.],\n",
       "         [-11., -23.,  11.,  23.]]),\n",
       " tensor([[-45., -23.,  45.,  23.],\n",
       "         [-32., -32.,  32.,  32.],\n",
       "         [-23., -45.,  23.,  45.]]),\n",
       " tensor([[-91., -45.,  91.,  45.],\n",
       "         [-64., -64.,  64.,  64.],\n",
       "         [-45., -91.,  45.,  91.]]),\n",
       " tensor([[-181.,  -91.,  181.,   91.],\n",
       "         [-128., -128.,  128.,  128.],\n",
       "         [ -91., -181.,   91.,  181.]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes=((32,),(64,),(128,),(256,))\n",
    "aspect_ratios=((0.5, 1.0, 2.0),)* len(sizes)\n",
    "# anchor模板是怎样生成锚框的\n",
    "for size, aspect_ratio in zip(sizes, aspect_ratios):\n",
    "    print(size,aspect_ratio)\n",
    "    size = torch.as_tensor(size)\n",
    "    aspect_ratio = torch.as_tensor(aspect_ratio)\n",
    "    print(size.shape, aspect_ratio.shape)\n",
    "    print(size[None,:].shape, aspect_ratio[:,None].shape)\n",
    "\n",
    "# 根据anchor模板参数生成对应的anchors模板\n",
    "# 在特征图的每一个pixel还原到原图上的区域\n",
    "# 以区域的左上角点为中心生成对应模板的锚框\n",
    "from typing import List\n",
    "def generate_anchors(\n",
    "    scales: List[int],\n",
    "    aspect_ratios: List[float],\n",
    "    dtype: torch.dtype = torch.float32,\n",
    "    device: torch.device = torch.device(\"cpu\"),\n",
    "):\n",
    "    scales = torch.as_tensor(scales, dtype=dtype, device=device)\n",
    "    aspect_ratios = torch.as_tensor(aspect_ratios, dtype=dtype, device=device)\n",
    "    h_ratios = torch.sqrt(aspect_ratios)\n",
    "    w_ratios = 1 / h_ratios\n",
    "\n",
    "    ws = (w_ratios[:, None] * scales[None, :]).view(-1)\n",
    "    hs = (h_ratios[:, None] * scales[None, :]).view(-1)\n",
    "\n",
    "    base_anchors = torch.stack([-ws, -hs, ws, hs], dim=1) / 2\n",
    "    return base_anchors.round()\n",
    "cell_anchors = [\n",
    "    generate_anchors(\n",
    "        scales, aspect_ratio) for scales, aspect_ratio in zip(sizes, aspect_ratios)\n",
    "    ]\n",
    "cell_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_sizes\n",
      "torch.Size([40, 80])\n",
      "torch.Size([20, 40])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([5, 10])\n",
      "***\n",
      "strides\n",
      "[tensor(8), tensor(8)]\n",
      "[tensor(16), tensor(16)]\n",
      "[tensor(32), tensor(32)]\n",
      "[tensor(64), tensor(64)]\n"
     ]
    }
   ],
   "source": [
    "# 原图尺寸\n",
    "image_size = (320,640)\n",
    "# 经过FPN提取的特征图\n",
    "feature_maps = backbone(torch.rand(4,3,320,640))\n",
    "grid_sizes = list([v.shape[-2:] for v in feature_maps.values()])\n",
    "print('grid_sizes')\n",
    "for i in grid_sizes:\n",
    "    print(i\n",
    "    )\n",
    "print('***')\n",
    "# 获取每一个特征图的每一个像素坐标相对于原图的坐标的比例\n",
    "strides = [\n",
    "    [\n",
    "        torch.tensor(image_size[0] // g[0], dtype=torch.int64),\n",
    "        torch.tensor(image_size[1] // g[1], dtype=torch.int64),\n",
    "    ]\n",
    "    for g in grid_sizes\n",
    "]\n",
    "print('strides')\n",
    "for i in strides:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征图数量和布局、anchor数量要一致\n",
    "# 每一个尺度的特征图都对应不同的布局，使用对应的anchor模板，以下标对应\n",
    "assert (len(grid_sizes) == len(strides) == len(cell_anchors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征图的大小 还原回原图的步距 对应这个特征图的anchor模板 生成对应数量的锚框\n",
      "torch.Size([40, 80]) [tensor(8), tensor(8)] tensor([[-23., -11.,  23.,  11.],\n",
      "        [-16., -16.,  16.,  16.],\n",
      "        [-11., -23.,  11.,  23.]]) 12800\n",
      "特征图的大小 还原回原图的步距 对应这个特征图的anchor模板 生成对应数量的锚框\n",
      "torch.Size([20, 40]) [tensor(16), tensor(16)] tensor([[-45., -23.,  45.,  23.],\n",
      "        [-32., -32.,  32.,  32.],\n",
      "        [-23., -45.,  23.,  45.]]) 3200\n",
      "特征图的大小 还原回原图的步距 对应这个特征图的anchor模板 生成对应数量的锚框\n",
      "torch.Size([10, 20]) [tensor(32), tensor(32)] tensor([[-91., -45.,  91.,  45.],\n",
      "        [-64., -64.,  64.,  64.],\n",
      "        [-45., -91.,  45.,  91.]]) 800\n",
      "特征图的大小 还原回原图的步距 对应这个特征图的anchor模板 生成对应数量的锚框\n",
      "torch.Size([5, 10]) [tensor(64), tensor(64)] tensor([[-181.,  -91.,  181.,   91.],\n",
      "        [-128., -128.,  128.,  128.],\n",
      "        [ -91., -181.,   91.,  181.]]) 200\n"
     ]
    }
   ],
   "source": [
    "anchors_over_all_feature_maps = []\n",
    "#特征图大小，特征图相对于原图的步距，每一个网格的anchor模板\n",
    "for size, stride, base_anchors in zip(grid_sizes, strides, cell_anchors):\n",
    "    print(\"特征图的大小\", \"还原回原图的步距\", \"对应这个特征图的anchor模板\",\"生成对应数量的锚框\")\n",
    "    print(size, stride, base_anchors, size[0]*size[1]*len(cell_anchors))\n",
    "\n",
    "    grid_height, grid_width = size\n",
    "    stride_height, stride_width = stride\n",
    "    device = base_anchors.device\n",
    "\n",
    "    # For output anchor, compute [x_center, y_center, x_center, y_center]\n",
    "    # 计算特征图每一个pixel还原回原图时的中心坐标位置x,y\n",
    "    shifts_x = torch.arange(0, grid_width, dtype=torch.int32, device=device) * stride_width\n",
    "    shifts_y = torch.arange(0, grid_height, dtype=torch.int32, device=device) * stride_height\n",
    "    \n",
    "    shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x, indexing=\"ij\")\n",
    "    shift_x = shift_x.reshape(-1)\n",
    "    shift_y = shift_y.reshape(-1)\n",
    "    shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=1)\n",
    "\n",
    "    # For every (base anchor, output anchor) pair,\n",
    "    # offset each zero-centered base anchor by the center of the output anchor.\n",
    "    anchors_over_all_feature_maps.append((shifts.view(-1, 1, 4) + base_anchors.view(1, -1, 4)).reshape(-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9600, 4])\n",
      "torch.Size([2400, 4])\n",
      "torch.Size([600, 4])\n",
      "torch.Size([150, 4])\n"
     ]
    }
   ],
   "source": [
    "for i in anchors_over_all_feature_maps:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98fb0aec2b4fc0bc91cf6dc42bf2af3676c87e4933cf6f400aa3ed207c96f75f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
